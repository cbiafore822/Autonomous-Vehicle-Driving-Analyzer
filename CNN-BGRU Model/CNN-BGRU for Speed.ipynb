{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras as kr\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Input, Bidirectional, TimeDistributed, GRU, LSTM, BatchNormalization, ConvLSTM2D, Concatenate\n",
    "from subprocess import call\n",
    "import glob\n",
    "import Automold as am\n",
    "import Helpers as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't need to run this if the data of optical flow is ready\n",
    "try:\n",
    "    if not os.path.exists('./data_comma/optical_flow_frames'):\n",
    "        os.makedirs('./data_comma/optical_flow_frames')\n",
    "except OSError:\n",
    "    print('Where is the data directory?')\n",
    "counter = 0\n",
    "# Get a VideoCapture object from video and store it in vs\n",
    "vc = cv2.VideoCapture('./data_comma/train.mp4')\n",
    "# Read first frame\n",
    "ret, first_frame = vc.read()\n",
    "# Scale and resize image\n",
    "resize_dim = 600\n",
    "max_dim = max(first_frame.shape)\n",
    "scale = resize_dim/max_dim\n",
    "first_frame = cv2.resize(first_frame, None, fx=scale, fy=scale)\n",
    "# Convert to gray scale \n",
    "prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# Create mask\n",
    "mask = np.zeros_like(first_frame)\n",
    "# Sets image saturation to maximum\n",
    "mask[..., 1] = 255\n",
    "\n",
    "\n",
    "out = cv2.VideoWriter('Optical.mp4',-1,1,(600, 600))\n",
    "\n",
    "while(1):\n",
    "    # Read a frame from video\n",
    "    ret, frame = vc.read()\n",
    "    \n",
    "    # Convert new frame format`s to gray scale and resize gray frame obtained\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, None, fx=scale, fy=scale)\n",
    "\n",
    "    # Calculate dense optical flow by Farneback method\n",
    "    # https://docs.opencv.org/3.0-beta/modules/video/doc/motion_analysis_and_object_tracking.html#calcopticalflowfarneback\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, pyr_scale = 0.5, levels = 3, winsize = 15, iterations = 5, poly_n = 5, poly_sigma = 1.2, flags = 0)\n",
    "    #flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, pyr_scale = 0.5, levels = 5, winsize = 11, iterations = 5, poly_n = 5, poly_sigma = 1.1, flags = 0)\n",
    "    # Compute the magnitude and angle of the 2D vectors\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Set image hue according to the optical flow direction\n",
    "    mask[..., 0] = angle * 180 / np.pi / 2\n",
    "    # Set image value according to the optical flow magnitude (normalized)\n",
    "    mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    # Convert HSV to RGB (BGR) color representation\n",
    "    rgb = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    # Resize frame size to match dimensions\n",
    "    frame = cv2.resize(frame, None, fx=scale, fy=scale)\n",
    "    \n",
    "    # Open a new window and displays the output frame\n",
    "    dense_flow = cv2.addWeighted(frame, 1,rgb, 2, 0)\n",
    "    cv2.imshow(\"Dense optical flow\", dense_flow)\n",
    "    out.write(dense_flow)\n",
    "    # Update previous frame\n",
    "    prev_gray = gray\n",
    "    # Frame are read by intervals of 1 millisecond. The programs breaks out of the while loop when the user presses the 'q' key\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q') or ret is False:\n",
    "        break\n",
    "    else:\n",
    "        name = './data_comma/optical_flow_frames/Frame' + str(counter) + '.jpg'\n",
    "        cv2.imwrite(name, dense_flow)\n",
    "        #train_label.write(label_id[counter])\n",
    "        counter += 1\n",
    "# The following frees up resources and closes all windows\n",
    "vc.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data extraction for optical flow\n",
    "\n",
    "frame_dir = './data_comma/optical_flow_frames'\n",
    "label_dir = './data_comma/train.txt'\n",
    "labels_file = './data_comma/OpticalData.csv'\n",
    "\n",
    "def load_data(labels_file, test_size):\n",
    "    \"\"\"\n",
    "    Display a list of images in a single figure with matplotlib.\n",
    "        Parameters:\n",
    "            labels_file: The labels CSV file.\n",
    "            test_size: The size of the testing set.\n",
    "    \"\"\"\n",
    "    labels = pd.read_csv(labels_file)\n",
    "    X = labels['VideoFrames'].values\n",
    "    y = labels['Speeds'].values\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "    X_train, X_test, y_train, y_test = X[:int(len(X)*(1-test_size/2))], X[int(len(X)*(1-test_size)):], y[:int(len(X)*(1-test_size/2))], y[int(len(X)*(1-test_size)):]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def load_image(data_dir, image_file):\n",
    "    \"\"\"\n",
    "    Load RGB image.\n",
    "        Parameters:\n",
    "            data_dir: The directory where the images are.\n",
    "            image_file: The image file name.\n",
    "    \"\"\"\n",
    "    return mpimg.imread(os.path.join(data_dir, image_file.strip()))\n",
    "\n",
    "\n",
    "data = load_data(labels_file, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data extraction for normal data\n",
    "frame_dir = './data_comma/data_frames'\n",
    "#label_dir = './data_comma/train.txt'\n",
    "labels_file = './data_comma/Data.csv'\n",
    "\n",
    "def load_data(labels_file, test_size):\n",
    "    \"\"\"\n",
    "    Display a list of images in a single figure with matplotlib.\n",
    "        Parameters:\n",
    "            labels_file: The labels CSV file.\n",
    "            test_size: The size of the testing set.\n",
    "    \"\"\"\n",
    "    labels = pd.read_csv(labels_file)\n",
    "    X = labels['VideoFrames'].values\n",
    "    y = labels['Speeds'].values\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "    X_train, X_test, y_train, y_test = X[:int(len(X)*(1-test_size/2))], X[int(len(X)*(1-test_size)):], y[:int(len(X)*(1-test_size/2))], y[int(len(X)*(1-test_size)):]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def load_image(data_dir, image_file):\n",
    "    \"\"\"\n",
    "    Load RGB image.\n",
    "        Parameters:\n",
    "            data_dir: The directory where the images are.\n",
    "            image_file: The image file name.\n",
    "    \"\"\"\n",
    "    return mpimg.imread(os.path.join(data_dir, image_file.strip()))\n",
    "\n",
    "\n",
    "data = load_data(labels_file, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of video frames\n",
    "\n",
    "def random_flip(data_dir, image_file, speed):\n",
    "    \"\"\"\n",
    "    Randomly flipping the input image horizontaly, with steering angle adjustment.\n",
    "        Parameters:\n",
    "            image: The input image.\n",
    "            steering_angle: The steering angle related to the input image.\n",
    "    \"\"\"\n",
    "    image = load_image(data_dir, image_file)\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        speed = speed\n",
    "    return image, speed\n",
    "\n",
    "def random_shift(image, speed, range_x, range_y):\n",
    "    \"\"\"\n",
    "    Shifting (Translating) the input images, with steering angle adjustment.\n",
    "        Parameters:\n",
    "            image: The input image.\n",
    "            steering_angle: The steering angle related to the input image.\n",
    "            range_x: Horizontal translation range.\n",
    "            range_y: Vertival translation range.\n",
    "    \"\"\"\n",
    "    trans_x = range_x * (np.random.rand() - 0.3)\n",
    "    trans_y = range_y * (np.random.rand() - 0.3)\n",
    "    speed += trans_x * 0.002\n",
    "    trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])\n",
    "    height, width = image.shape[:2]\n",
    "    image = cv2.warpAffine(image, trans_m, (width, height))\n",
    "    return image, speed\n",
    "\n",
    "def random_shadow(image):\n",
    "    \"\"\"\n",
    "    Adding shadow to the input image.\n",
    "        Parameters:\n",
    "            image: The input image.\n",
    "    \"\"\"\n",
    "    bright_factor = 0.75\n",
    "    x = random.randint(0, image.shape[1])\n",
    "    y = random.randint(0, image.shape[0])\n",
    "    width = random.randint(image.shape[1], image.shape[1])\n",
    "    if(x + width > image.shape[1]):\n",
    "        x = image.shape[1] - x\n",
    "    height = random.randint(image.shape[0], image.shape[0])\n",
    "    if(y + height > image.shape[0]):\n",
    "        y = image.shape[0] - y\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    image[y:y+height,x:x+width,2] = image[y:y+height,x:x+width,2]*bright_factor\n",
    "    return cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def random_brightness(image):\n",
    "    \"\"\"\n",
    "    Altering the brightness of the input image.\n",
    "        Parameters:\n",
    "            image: The input image.\n",
    "    \"\"\"\n",
    "    # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).\n",
    "    image= am.brighten(image, 0.56)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    #ratio = 1.3 + (np.random.rand() - 0.05)\n",
    "    ratio = 1.25\n",
    "    hsv[:,:,2] =  hsv[:,:,2] * ratio\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def augument(data_dir, image_file, speed, range_x=100, range_y=10):\n",
    "    \"\"\"\n",
    "    Generate an augumented image and adjust the associated steering angle.\n",
    "        Parameters:\n",
    "            data_dir: The directory where the images are.\n",
    "            center: Center image.\n",
    "            left: Left image.\n",
    "            right: Right image\n",
    "            steering_angle: The steering angle related to the input frame.\n",
    "            range_x (Default = 100): Horizontal translation range.\n",
    "            range_y (Default = 10): Vertival translation range.\n",
    "    \"\"\"\n",
    "    image, speed = random_flip(data_dir, image_file, speed)\n",
    "    image, speed = random_shift(image, speed, range_x, range_y)\n",
    "    image = random_shadow(image)\n",
    "    image = random_brightness(image)\n",
    "    return image, speed\n",
    "\n",
    "def preprocess(img):\n",
    "    \"\"\"\n",
    "    Preprocessing (Crop - Resize - Convert to YUV) the input image.\n",
    "        Parameters:\n",
    "            img: The input image to be preprocessed.\n",
    "    \"\"\"\n",
    "    # Cropping the image\n",
    "    img = img[100:360, :-90, :]\n",
    "    # Resizing the image\n",
    "    img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)\n",
    "    # Converting the image to YUV\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #img =cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    return img\n",
    "\n",
    "batch_size, time_step = 20, 4\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 100, 220, 3\n",
    "INPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
    "INPUT_SHAPE1 = (time_step, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
    "INPUT_SHAPE2 = (time_step,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out the processed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image(frame_dir, str(data[0][1116]))\n",
    "def display(image, angle, label):\n",
    "    plt.imshow(image)\n",
    "    #plt.xlabel(\"Vehicle Speed: {:.5f}\".format(angle)+\"m/s\")\n",
    "    #plt.title(label)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "veh_speed = data[2][1116]\n",
    "plt.figure(figsize=(10,6))\n",
    "display(preprocess(image), veh_speed, \"Training example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check the images\n",
    "image = load_image(frame_dir, str(data[0][856]))\n",
    "speed = data[2][156]\n",
    "label = \"No process\"\n",
    "plt.figure(figsize=(6,4)), display(image, speed, label)\n",
    "\n",
    "image1 = augument(frame_dir, str(data[0][1856]), data[2][12256])\n",
    "label = \"Processed\"\n",
    "plt.figure(figsize=(6,4)),display(image1[0], speed, label)\n",
    "\n",
    "image2, veh_speed = augument(frame_dir, str(data[0][856]), data[2][12256])\n",
    "image2 = preprocess(image2)\n",
    "label = \"Augmented\"\n",
    "plt.figure(figsize=(6,4)),display(image2, veh_speed, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A couple NNs to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CNN-BGRU model\n",
    "\n",
    "def N2N_model1():\n",
    "    data = Input(shape=INPUT_SHAPE1)\n",
    "    convs = Sequential()\n",
    "    convs.add(Lambda(lambda x: x/127.5-1.0, input_shape=INPUT_SHAPE))\n",
    "    convs.add(Conv2D(24, (5, 5), activation='elu', padding = 'same', strides=(2, 2)))\n",
    "    convs.add(Conv2D(36, (5, 5), activation='elu', padding = 'same', strides=(2, 2)))\n",
    "    convs.add(Conv2D(48, (5, 5), activation='elu', padding = 'same', strides=(2, 2)))\n",
    "    convs.add(Dropout(0.5))\n",
    "    convs.add(Conv2D(64, (3, 3), activation='elu', padding = 'same', strides=(1, 1)))\n",
    "    convs.add(Conv2D(64, (3, 3), activation='elu', padding = 'same', strides=(1, 1)))\n",
    "    convs.add(MaxPooling2D((2, 2), strides=(1,1)))\n",
    "    #convs.add(GlobalAveragePooling2D())\n",
    "    convs.add(Dropout(0.5))\n",
    "    convs.add(Flatten())\n",
    "    \n",
    "    recu = TimeDistributed(convs)(data)\n",
    "    recu = Bidirectional(GRU(300, activation='elu', recurrent_activation='hard_sigmoid', return_sequences=False))(recu)\n",
    "    \n",
    "    recu = Dropout(0.5)(recu)\n",
    "    #recu = Dense(1000)(recu)\n",
    "    #recu = Dropout(0.3)(recu)\n",
    "    recu = Dense(120, activation='elu')(recu)\n",
    "    recu = Dropout(0.3)(recu)\n",
    "    recu = Dense(60, activation='elu')(recu)\n",
    "    recu = Dropout(0.3)(recu)\n",
    "    recu = Dense(10)(recu)\n",
    "    recu = Dropout(0.1)(recu)\n",
    "    recu = Dense(1)(recu)\n",
    "\n",
    "    model = Model(inputs=data, outputs=recu)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include extra data with speed in previous time steps\n",
    "\n",
    "def N2N_model1_1():\n",
    "    data = Input(shape=INPUT_SHAPE1)\n",
    "    convs = Sequential()\n",
    "    convs.add(Lambda(lambda x: x/127.5-1.0, input_shape=INPUT_SHAPE))\n",
    "    convs.add(Conv2D(24, (5, 5), activation='relu', padding = 'same', strides=(2, 2)))\n",
    "    convs.add(Conv2D(48, (5, 5), activation='relu', padding = 'same', strides=(2, 2)))\n",
    "    convs.add(Conv2D(48, (5, 5), activation='relu', padding = 'same', strides=(2, 2)))\n",
    "    convs.add(Dropout(0.5))\n",
    "    convs.add(Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
    "    convs.add(Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
    "    convs.add(MaxPooling2D((2, 2), strides=(1,1), padding='same'))\n",
    "    #convs.add(GlobalAveragePooling2D())\n",
    "    convs.add(Flatten())\n",
    "    convs.add(Dropout(0.5))\n",
    "    \n",
    "    recu = TimeDistributed(convs)(data)\n",
    "    recu = Bidirectional(GRU(226, activation='relu', recurrent_activation='hard_sigmoid', return_sequences=False))(recu)\n",
    "    recu = Dropout(0.5)(recu)\n",
    "    \n",
    "    inp2 = Input(shape=INPUT_SHAPE2)\n",
    "    Conn = (Dense(20, activation='relu'))(inp2)\n",
    "    \n",
    "    recu1 = Concatenate()([recu, Conn])\n",
    "    recu1 = Dropout(0.5)(recu1)\n",
    "    recu1 = Dense(128, activation='relu')(recu1)\n",
    "    recu1 = Dropout(0.5)(recu1)\n",
    "    recu1 = Dense(64, activation='relu')(recu1)\n",
    "    recu1 = Dropout(0.3)(recu1)\n",
    "    recu1 = Dense(10, activation='relu')(recu1)\n",
    "    #recu1 = Dropout(0.1)(recu1)\n",
    "    recu1 = Dense(1)(recu1)\n",
    "\n",
    "    model = Model(inputs=[data, inp2], outputs=recu1)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following ones are hard to train, but can try them out...\n",
    "def N2N_model2():\n",
    "    model = Sequential()\n",
    "    #model.add(Lambda(lambda x: x/127.5-1.0, input_shape=INPUT_SHAPE1))\n",
    "    model.add(BatchNormalization(input_shape=INPUT_SHAPE1))\n",
    "    #model.add(ConvLSTM2D(filters=36, kernel_size=(5,5), padding = 'same', return_sequences = True, strides=(2, 2)))\n",
    "    #model.add(ConvLSTM2D(filters=24, kernel_size=(5,5), padding = 'same', return_sequences = True, strides=(2, 2)))\n",
    "    model.add(ConvLSTM2D(filters=36, kernel_size=(5,5), padding = 'same', return_sequences = True, strides=(2, 2)))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(ConvLSTM2D(filters=48, kernel_size=(3,3), padding = 'same', return_sequences = True))\n",
    "    model.add(ConvLSTM2D(filters=64, kernel_size=(3,3), padding = 'same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    #.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    #model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def N2N_model3():\n",
    "    inp1 = Input(shape=INPUT_SHAPE1)\n",
    "    Conv = (Lambda(lambda x: x/127.5-1.0))(inp1)\n",
    "    Conv = (ConvLSTM2D(filters=36, kernel_size=(5,5), padding = 'same', return_sequences = True, strides=(2, 2)))(Conv)\n",
    "    Conv = (ConvLSTM2D(filters=36, kernel_size=(3,3), padding = 'same', return_sequences = True, strides=(2, 2)))(Conv)\n",
    "    Conv = (ConvLSTM2D(filters=64, kernel_size=(3,3), padding = 'same'))(Conv)\n",
    "    Conv = Flatten()(Conv)\n",
    "    Conv = (Dense(50, activation='relu'))(Conv)\n",
    "    \n",
    "    inp2 = Input(shape=INPUT_SHAPE2)\n",
    "    Conn = (Dense(50, activation='relu'))(inp2)\n",
    "    \n",
    "    Merge = Concatenate()([Conv, Conn])\n",
    "    Merge = Dense(10, activation='relu')(Merge)\n",
    "    Merge = Dense(1)(Merge)\n",
    "    \n",
    "    model = Model(inputs=[inp1, inp2], outputs=Merge)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = Input(shape=INPUT_SHAPE1)\n",
    "Conv = (Lambda(lambda x: x/127.5-1.0))(inp1)\n",
    "Conv = (ConvLSTM2D(filters=36, kernel_size=(5,5), padding = 'same', return_sequences = True, strides=(2, 2)))(Conv)\n",
    "Conv = (ConvLSTM2D(filters=36, kernel_size=(3,3), padding = 'same', return_sequences = True, strides=(2, 2)))(Conv)\n",
    "Conv = (ConvLSTM2D(filters=64, kernel_size=(3,3), padding = 'same'))(Conv)\n",
    "Conv = Flatten()(Conv)\n",
    "Conv = (Dense(50, activation='relu'))(Conv)\n",
    "    \n",
    "inp2 = Input(shape=INPUT_SHAPE2)\n",
    "Conn = (Dense(50, activation='relu'))(inp2)\n",
    "    \n",
    "Merge = Concatenate()([Conv, Conn])\n",
    "Merge = Dense(10, activation='relu')(Merge)\n",
    "Merge = Dense(1)(Merge)\n",
    "    \n",
    "model = Model(inputs=[inp1, inp2], outputs=Merge)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training usage for N2Nmodel1 and N2Nmodel2\n",
    "\n",
    "batch_size, time_step = 20, 4\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 100, 220, 3\n",
    "INPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
    "INPUT_SHAPE1 = (time_step, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
    "INPUT_SHAPE2 = (time_step,)\n",
    "\n",
    "samples_per_epoch = len(data[0])//batch_size\n",
    "nb_epoch = 50\n",
    "\n",
    "def batcher(data_dir, image_paths, speeds, batch_size, training_flag):\n",
    "    images = np.empty([batch_size, time_step, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])\n",
    "    veh_speeds = np.empty(batch_size)\n",
    "    while True:\n",
    "        i = 0\n",
    "        for j in np.random.permutation(np.linspace(time_step, image_paths.shape[0], image_paths.shape[0]-time_step+1, dtype=int)):\n",
    "            idx_X = np.linspace(j-time_step,j-1,time_step, dtype = int)\n",
    "            for index in range(0,idx_X.shape[0]):\n",
    "                ii = idx_X[index]\n",
    "                image = image_paths[ii]\n",
    "                veh_speed = speeds[ii]\n",
    "                if training_flag and np.random.rand() < 0.6:\n",
    "                    image, veh_speed = augument(data_dir, image, veh_speed)\n",
    "                else:\n",
    "                    image = load_image(data_dir, image)\n",
    "                images[i,index,:] = preprocess(image)\n",
    "            veh_speeds[i] = veh_speed\n",
    "            i += 1\n",
    "            if i == batch_size:\n",
    "                break\n",
    "        yield images, veh_speeds\n",
    "        \n",
    "def train_model(model, X_train, X_valid, y_train, y_valid):\n",
    "    checkpoint = ModelCheckpoint('model_best.h5',\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='auto')\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=1.05e-4,beta_1=0.9, beta_2=0.999, decay=0., amsgrad=False))\n",
    "    history = model.fit_generator(batcher(frame_dir, X_train, y_train, batch_size, True),\n",
    "                        samples_per_epoch,\n",
    "                        epochs = nb_epoch,\n",
    "                        max_queue_size=1,\n",
    "                        validation_data=batcher(frame_dir, X_valid, y_valid, batch_size, False),\n",
    "                        #nb_val_samples=len(X_valid),\n",
    "                        validation_steps=len(X_valid)//batch_size,\n",
    "                        use_multiprocessing = False,\n",
    "                        callbacks=[checkpoint],\n",
    "                        verbose=1)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training usage for N2Nmodel1_1 and N2Nmodel3\n",
    "\n",
    "samples_per_epoch = len(data[0])//batch_size\n",
    "nb_epoch = 10\n",
    "\n",
    "def batcher1(data_dir, image_paths, speeds, batch_size, time_step, training_flag):\n",
    "    images = np.empty([batch_size, time_step, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])\n",
    "    v_pre = np.empty([batch_size, time_step])\n",
    "    veh_speeds = np.empty(batch_size)\n",
    "    while True:\n",
    "        i = 0\n",
    "        for j in np.random.permutation(np.linspace(time_step, image_paths.shape[0], image_paths.shape[0]-time_step+1, dtype=int)):\n",
    "            idx_X = np.linspace(j-time_step,j-1,time_step, dtype = int)\n",
    "            for index in range(0,idx_X.shape[0]):\n",
    "                ii = idx_X[index]\n",
    "                image = image_paths[ii]\n",
    "                veh_speed = speeds[ii]\n",
    "                if training_flag and np.random.rand() < 0.68:\n",
    "                    image, veh_speed = augument(data_dir, image, veh_speed)\n",
    "                else:\n",
    "                    image = load_image(data_dir, image)\n",
    "                images[i,index,:] = preprocess(image)\n",
    "                if index==0:\n",
    "                    v_pre[i,index] = veh_speed\n",
    "                else:\n",
    "                    v_pre[i,index] = speeds[idx_X[index-1]]\n",
    "            veh_speeds[i] = veh_speed\n",
    "            #temp = veh_speeds[i]\n",
    "            i += 1\n",
    "            if i == batch_size:\n",
    "                break\n",
    "        yield [images, v_pre], veh_speeds\n",
    "        \n",
    "def train_model1(model, X_train, X_valid, y_train, y_valid, time_step):\n",
    "    '''\n",
    "        checkpoint = ModelCheckpoint('model-{val_loss:03f}.h5',\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=0,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='auto')\n",
    "    '''\n",
    "\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=1.05e-4,beta_1=0.9, beta_2=0.999, decay=0., amsgrad=False))\n",
    "    history = model.fit_generator(batcher1(frame_dir, X_train, y_train, batch_size, time_step, True),\n",
    "                        #steps_per_epoch = len(X_train)//batch_size,\n",
    "                        samples_per_epoch,\n",
    "                        epochs = nb_epoch,\n",
    "                        max_queue_size=1,\n",
    "                        validation_data=batcher1(frame_dir, X_valid, y_valid, batch_size, time_step, False),\n",
    "                        #nb_val_samples=len(X_valid),\n",
    "                        validation_steps=len(X_valid)//batch_size,\n",
    "                        use_multiprocessing = False,\n",
    "                        #callbacks=[checkpoint],\n",
    "                        verbose=1)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "model = N2N_model1()\n",
    "history = train_model(model, *data)\n",
    "model.save('N2Ncomma_speed.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model for testing N2Nmodel1 and N2Nmodel2\n",
    "# Can skip the training and load the trained model, but make sure you load the data based on the input of the model\n",
    "# For the model 'N2Nmodel_speed.h5', the input shape will be (batch size, time_step=4, image_height=66,image_height=220,channels=3)\n",
    "import tensorflow\n",
    "def getTestData(data_dir, image_paths, speeds, t_size, time_step, start):\n",
    "    images = np.empty([t_size, time_step, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])\n",
    "    veh_speeds = np.empty(t_size)\n",
    "    i, i_start = 0, start\n",
    "    for j in np.linspace(time_step, image_paths.shape[0], image_paths.shape[0]-time_step+1, dtype=int):\n",
    "        idx_X = np.linspace(j-time_step,j-1,time_step, dtype = int)\n",
    "        for index in range(0,idx_X.shape[0]):\n",
    "            ii = idx_X[index]\n",
    "            image = image_paths[ii]\n",
    "            veh_speed = speeds[ii]\n",
    "            if np.random.rand() < 0.6:\n",
    "                image, veh_speed = augument(data_dir, image, veh_speed)\n",
    "            else:\n",
    "                image = load_image(data_dir, image)\n",
    "            images[i,index,:] = preprocess(image)\n",
    "        veh_speeds[i] = veh_speed\n",
    "        i += 1\n",
    "        i_start += 1\n",
    "        if i_start == start+t_size:\n",
    "            break\n",
    "    return images, veh_speeds\n",
    "\n",
    "start1, start2 = 0, 0\n",
    "t_size1, t_size2 = 19000, 2000\n",
    "data_Train = getTestData(frame_dir, data[0], data[2], t_size1, time_step, start1)\n",
    "data_Test = getTestData(frame_dir, data[1], data[3], t_size2, time_step, start2)\n",
    "\n",
    "#data_Test[0].shape\n",
    "model =  tensorflow.keras.models.load_model('N2Ncomma_1120.h5')\n",
    "speed_train = model.predict(data_Train[0])\n",
    "speed_test = model.predict(data_Test[0])\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(speed_train, label='Speed from model')\n",
    "plt.plot(data_Train[1], label='Groud truth speed')\n",
    "plt.title('Trained model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(speed_test, label='Speed from model')\n",
    "plt.plot(data_Test[1], label='Groud truth speed')\n",
    "plt.title('Testing model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(history1112.history['loss'], label='MSE_training')\n",
    "plt.plot(history1112.history['val_loss'], label='MSE_validating')\n",
    "plt.ylim(-1,50)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_Test[0].shape\n",
    "model =  tensorflow.keras.models.load_model('N2Ncomma_1120.h5')\n",
    "speed_train = model.predict(data_Train[0])\n",
    "#speed_test = model.predict(data_Test[0])\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(speed_train, label='Speed from model')\n",
    "plt.plot(data_Train[1], label='Groud truth speed')\n",
    "plt.title('Trained model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#plt.figure(figsize=(16,5))\n",
    "#plt.plot(speed_test, label='Speed from model')\n",
    "#plt.plot(data_Test[1], label='Groud truth speed')\n",
    "#plt.title('Testing model')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(history1112.history['loss'], label='MSE_training')\n",
    "plt.plot(history1112.history['val_loss'], label='MSE_validating')\n",
    "plt.ylim(-1,50)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model testing for N2Nmodel1_1 and N2Nmodel3\n",
    "\n",
    "def getTestData1(data_dir, image_paths, speeds, t_size, time_step, start):\n",
    "    images = np.empty([t_size, time_step, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])\n",
    "    v_pre = np.empty([t_size, time_step])\n",
    "    veh_speeds = np.empty(t_size)\n",
    "    i, i_start = 0, start\n",
    "    for j in np.linspace(time_step, image_paths.shape[0], image_paths.shape[0]-time_step+1, dtype=int):\n",
    "        idx_X = np.linspace(j-time_step,j-1,time_step, dtype = int)\n",
    "        for index in range(0,idx_X.shape[0]):\n",
    "            ii = idx_X[index]\n",
    "            image = image_paths[ii]\n",
    "            veh_speed = speeds[ii]\n",
    "            image = load_image(data_dir, image)\n",
    "            images[i,index,:] = preprocess(image)\n",
    "            if index==0:\n",
    "                v_pre[i,index] = veh_speed\n",
    "            else:\n",
    "                v_pre[i,index] = speeds[idx_X[index-1]]\n",
    "        veh_speeds[i] = veh_speed\n",
    "        i += 1\n",
    "        i_start += 1\n",
    "        if i_start == start+t_size:\n",
    "            break\n",
    "    return [images, v_pre], veh_speeds\n",
    "\n",
    "import tensorflow\n",
    "def getTestData(data_dir, image_paths, speeds, t_size, time_step, start):\n",
    "    images = np.empty([t_size, time_step, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])\n",
    "    veh_speeds = np.empty(t_size)\n",
    "    i, i_start = 0, start\n",
    "    for j in np.linspace(time_step, image_paths.shape[0], image_paths.shape[0]-time_step+1, dtype=int):\n",
    "        idx_X = np.linspace(j-time_step,j-1,time_step, dtype = int)\n",
    "        for index in range(0,idx_X.shape[0]):\n",
    "            ii = idx_X[index]\n",
    "            image = image_paths[ii]\n",
    "            veh_speed = speeds[ii]\n",
    "            if np.random.rand() < 0.6:\n",
    "                image, veh_speed = augument(data_dir, image, veh_speed)\n",
    "            else:\n",
    "                image = load_image(data_dir, image)\n",
    "            images[i,index,:] = preprocess(image)\n",
    "        veh_speeds[i] = veh_speed\n",
    "        i += 1\n",
    "        i_start += 1\n",
    "        if i_start == start+t_size:\n",
    "            break\n",
    "    return images, veh_speeds\n",
    "\n",
    "start1, start2 = 0, 0\n",
    "t_size = 1920\n",
    "\n",
    "#data_Train = getTestData(frame_dir, data[0], data[2], t_size, time_step, start1)\n",
    "#data_Test = getTestData(frame_dir, data[1], data[3], t_size, time_step, start2)\n",
    "\n",
    "#model = kr.models.load_model('n2nmodel8.h5')\n",
    "\n",
    "#model = tensorflow.keras.models.load_model('model_best.h5')\n",
    "\n",
    "#data_Train = getTestData1(frame_dir, data[0], data[2], t_size, time_step, start1)\n",
    "#data_Test = getTestData1(frame_dir, data[1], data[3], t_size, time_step, start2)\n",
    "#speed_train = model.predict([data_Train[0][0], data_Train[0][1]])\n",
    "#speed_test = model.predict([data_Test[0][0], data_Test[0][1]])\n",
    "\n",
    "#speed_train = model.predict(data_Train[0])\n",
    "speed_test = model.predict(data_Test[0])\n",
    "#plt.figure(figsize=(16,5))\n",
    "#plt.plot(speed_train, label='Speed from model')\n",
    "#plt.plot(data_Train[1], label='Groud truth speed')\n",
    "#plt.title('Trained model')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(speed_test, label='Speed from model')\n",
    "plt.plot(data_Test[1], label='Groud truth speed')\n",
    "#plt.title('Validation')\n",
    "plt.xlabel('Time step', fontsize=18)\n",
    "plt.ylabel('Speed (m/s)', fontsize=18)\n",
    "plt.legend(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animation use\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "#fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "for i in range(len(data_Train[0])):\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(speed_train.squeeze()[:i], linestyle='--', label='trained')\n",
    "    plt.plot(speed_test.squeeze()[:i], linestyle='--', label='tested')\n",
    "    #plt.legend()\n",
    "    if i > 10:\n",
    "        plt.xlim(i-10, i)\n",
    "    plt.show()\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
